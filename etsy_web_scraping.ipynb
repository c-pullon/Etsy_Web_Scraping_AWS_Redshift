{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a800f72",
   "metadata": {},
   "source": [
    "## Web Scraping Etsy, Cleaning the Data, and Uploading the data to AWS S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b69321b",
   "metadata": {},
   "source": [
    "In this project, I web scrape Etsy using BeautifulSoup and inspect the HTML elements to find the desired data. Information for product names and prices are found, and added to a DataFrame with Pandas. The data is then cleaned to make it readable and ready for further analysis.\n",
    "\n",
    "Following this, the DataFrame is converted to CSV and uploaded to an AWS S3 bucket by using the AWS SDK (Boto3) and establishing a connection with the S3 bucket. \n",
    "\n",
    "In Amazon Redshift, the data is loaded into a database after setting permisions allowing Redshift to connect with S3. Queries are then performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b1df3",
   "metadata": {},
   "source": [
    "#### Retrieving the HTML content and parsing the data with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cb0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the requests library to send a GET request to the URL to retrieve the HTML content\n",
    "\n",
    "URL = 'https://www.etsy.com/c/home-and-living'\n",
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b25d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the HTML so multiple GET requests are not needed\n",
    "\n",
    "scraped_file = \"scraped_file.html\"\n",
    "with open(scraped_file, \"w\", encoding = 'utf-8') as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95dcf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the HTML file and parse with Beautiful Soup to create a soup object\n",
    "\n",
    "soup = BeautifulSoup(open(scraped_file, 'r', encoding = 'utf-8'), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From inspecting the HTML elements, the products are found within h2 tags\n",
    "\n",
    "h2_tags = soup.find_all('h2')\n",
    "print(len(h2_tags))\n",
    "print(h2_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ce631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The web page shows 64 products, but 69 h2 tags are found. We can see that all the products have an h2 class \n",
    "# h2 class=\"wt-text-caption v2-listing-card__title wt-text-truncate\"\n",
    "\n",
    "product_class = 'wt-text-caption v2-listing-card__title wt-text-truncate'\n",
    "products = soup.find_all('h2',{'class': product_class})\n",
    "\n",
    "# We can now see that the correct products have been found\n",
    "\n",
    "len(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff2dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For finding the product prices, inspecting the element shows that the price is contained within a span tag, specifically\n",
    "# <span class=\"currency-value\">\n",
    "\n",
    "price_class = 'currency-value'\n",
    "prices= soup.find_all('span', {'class': price_class})\n",
    "print(len(prices))\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prices being returned also include the original price before any discount. This is not needed. The real price is found within\n",
    "# p tag, specifically \"wt-text-title-01 lc-price\"\n",
    "\n",
    "# The discounted price is within \"wt-text-caption search-collage-promotion-price wt-text-slime wt-text-truncate wt-no-wrap\"\n",
    "\n",
    "original_price_class = 'wt-text-caption search-collage-promotion-price wt-text-slime wt-text-truncate wt-no-wrap'\n",
    "real_price_class = 'wt-text-title-01 lc-price'\n",
    "real_prices = soup.find_all('p', {'class': real_price_class})\n",
    "len(real_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e103e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64 prices being returned matches with the number of products, but it still contains the discounted price and original price.\n",
    "# Using the decompose method from beautiful soup, we can filter out the unneeded information\n",
    "\n",
    "for p in soup.find_all('p', {'class': original_price_class}):\n",
    "    p.decompose()\n",
    "\n",
    "real_prices = soup.find_all('p', {'class': real_price_class})\n",
    "\n",
    "# Now we can see only the correct prices are showing, the original prices have been discardedb\n",
    "\n",
    "real_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724ef22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_prices = soup.find_all('span', {'class': price_class})\n",
    "print(len(real_prices))\n",
    "real_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef62af05",
   "metadata": {},
   "source": [
    "#### Adding the required data to a DataFrame and cleaning it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da605eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have the product names and prices, but they are surrounded by unneeded information. \n",
    "# Using the .text method will remove this. Strip will remove the white space\n",
    "\n",
    "product_names = []\n",
    "for product in products:\n",
    "    product_names.append(product.text.strip())\n",
    "    \n",
    "product_prices= []\n",
    "for product in real_prices:\n",
    "    product_prices.append(product.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1346b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with the product and price data\n",
    "\n",
    "data = {\n",
    "    'Product Name': product_names,\n",
    "    'Price': product_prices\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the 'Price' column to float\n",
    "df['Price'] = df['Price'].astype(float)\n",
    "\n",
    "# Replace commas with an empty string in the 'Product Name' column\n",
    "df['Product Name'] = df['Product Name'].str.replace(',', ' ')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b1b8b",
   "metadata": {},
   "source": [
    "#### Saving the DataFrame as a CSV file and uploading it to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacec9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame as a csv file\n",
    "\n",
    "df.to_csv('etsy_products.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c7933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an S3 client and upload CSV file\n",
    "import boto3\n",
    "\n",
    "\n",
    "region_name = 'us-east-1'\n",
    "\n",
    "# Create an S3 client with the specified region\n",
    "s3 = boto3.client('s3', region_name=region_name)\n",
    "\n",
    "bucket = 'web_scraping_projects'\n",
    "folder = 'Python/Etsy/'\n",
    "\n",
    "with open('etsy_products.csv', 'rb') as f:\n",
    "    s3.upload_fileobj(f, bucket, folder + 'etsy_products.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
